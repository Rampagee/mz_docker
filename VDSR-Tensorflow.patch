diff --git a/VDSR/demo.py b/VDSR/demo.py
index a9ee274..94ca3cb 100644
--- a/VDSR/demo.py
+++ b/VDSR/demo.py
@@ -5,74 +5,125 @@ import cv2
 import os
 import glob
 
-import VDSR.vdsr as vdsr
+import vdsr as vdsr
+
+from tensorflow.python.framework.graph_util import convert_variables_to_constants
+from tensorflow.python.framework.graph_util import remove_training_nodes
+
+def get_io_layers(graph_def):
+    """Retrive the input and output layers from a tensorflow GraphDef."""
+    inputs = [] # list entry nodes (placeholders)
+    nodes = set() # list all nodes
+    full_inputs = set() # list nodes that are inputs of others
+    for n in graph_def.node:
+        if n.op != "Const":
+            nodes.add(n.name)
+            for inp in n.input:
+                nodes.add(inp)
+                full_inputs.add(inp)
+            if len(n.input) == 0:
+                inputs.append(n)
+    outputs = nodes - full_inputs
+    return inputs, list(outputs)
+
 
 # Source: https://stackoverflow.com/questions/29100722/equivalent-im2double-function-in-opencv-python
 def im2double(image):
     info = np.iinfo(image.dtype) # Get the data type of the input image
     return image.astype(np.float32) / info.max # Divide all values by the largest possible value in the datatype
 
-def bicubic_sr(input, scale):
-    bicubic_output = np.clip(cv2.resize(input, None, fx=1.0 * scale, fy=1.0 * scale, interpolation=cv2.INTER_CUBIC), 0, 255).astype(np.uint8)
+def bicubic_sr(input, scale_x, scale_y):
+    bicubic_output = np.clip(cv2.resize(input, None, fx=1.0 * scale_x, fy=1.0 * scale_y, interpolation=cv2.INTER_CUBIC), 0, 255).astype(np.uint8)
 
     return bicubic_output
 
-def VDSR_sr(sess, VDSR, input, scale):
-    upscaled_rgb = np.clip(cv2.resize(input, None, fx=1.0 * scale, fy=1.0 * scale, interpolation=cv2.INTER_CUBIC), 0, 255).astype(np.uint8)
-
+def VDSR_preproc(iimg, scale_x, scale_y):
+    upscaled_rgb = np.clip(cv2.resize(iimg, None, fx=1.0 * scale_x, fy=1.0 * scale_y, interpolation=cv2.INTER_CUBIC), 0, 255).astype(np.uint8)
     upscaled_rgb = im2double(upscaled_rgb.astype(np.uint8))
+    return upscaled_rgb
 
-    VDSR_output = sess.run(VDSR.output, feed_dict={VDSR.X:np.expand_dims(upscaled_rgb, axis=0)})
-    VDSR_output = np.squeeze(VDSR_output, axis=0)
+def VDSR_sr(sess, VDSR, input ):
+    VDSR_output = sess.run(VDSR.outputs[0], feed_dict={"import/Placeholder:0":input})
     VDSR_output *= 255
-
     return VDSR_output
 
 if __name__ == '__main__':
     parser = argparse.ArgumentParser()
     parser.add_argument('--n_channel', type=int, default=3, help='-')
-    parser.add_argument('--scale', type=int, default=3, help='-')
+    parser.add_argument('--image_in', type=str, default='data/291/*.png', help='input image glob')
+    parser.add_argument('--out_x', type=int, default=256, help='output honrizontal resolution')
+    parser.add_argument('--out_y', type=int, default=256, help='output vertical resolution')
+    parser.add_argument('--batch', type=int, default=1, help='number of images within a batch')
+    parser.add_argument('--save_pb', action="store_true", help = 'freeze models save pb and quit', default=None)
     args, unknown = parser.parse_known_args()
 
-    scale = args.scale
+    out_x = args.out_x
+    out_y = args.out_y
 
     result_save_path = './demo_result'
     if not os.path.exists(result_save_path): os.makedirs(result_save_path)
 
-    print("Scale {}x !!".format(scale))
-    print("Please enter the path of the image's directory. Ex) '/data/test_images' ")
-    path = input("Enter the directory path: ")
-    print("Please enter the name of images. This version 'only' read '.png', 'jpg' extention and 'RGB' image! Ex) '0.png'")
-    print("If you want to read all images in the directory, enter '*.png' or '*.jpg'.")
-    name = input("Enter the image name: ")
-
-    image_path = path + '/' + name
-    images_list = glob.glob(image_path)
-
-    if not images_list:
-        print("Path is empty. Check that the directory or image name is correct.")
-    else:
+    if args.save_pb:
         VDSR = vdsr.VDSR(args)
         VDSR.neuralnet()
 
+        print("Loading checkpoint and saving frozen PB")
         sess = tf.Session()
         saver = tf.train.Saver()
         saver.restore(sess, './model/VDSR.ckpt')
+        minimal_graph = convert_variables_to_constants(sess, sess.graph_def, ["clip_by_value"])
+        minimal_graph = remove_training_nodes(minimal_graph)
+        tf.train.write_graph(minimal_graph, '.', 'vdsr.pb', as_text=False)
+        exit(0)
+
+    images_list = glob.glob(args.image_in)
+
+    if not images_list:
+        print("Path is empty. Check that the in argument is correct ({} given).".format(args.image_in))
+    else:
+        graph = tf.Graph()
+        with graph.as_default() as g:
+            graph_def = tf.GraphDef()
+            with open("vdsr.pb", "rb") as f:
+                graph_def.ParseFromString(f.read())
+            inout = get_io_layers(graph_def)
+#             print("input/output :", inout[1][0])
+            tf.import_graph_def(graph_def)
+        VDSR = graph.get_operation_by_name("import/" + inout[1][0])
+
+        sess = tf.Session(graph=graph)
+
+        total_img = 0
+        iimg_batch = list()
+        filename = list()
 
         for image in images_list:
-            filename = os.path.basename(image)[:-4]
+            total_img += 1
+
+            filename.append(os.path.basename(image)[:-4])
+            print("Process {}".format(filename[-1]))
 
             label = cv2.imread(image).astype(np.uint8)
-            #height, width =  label.shape[:2]
+            height, width =  label.shape[:2]
+            scale_x = 1.0 * out_x / width
+            scale_y = 1.0 * out_y / height
 
             if len(label.shape) != 3:
-                print("{}.png is not RGB 3 channel image".format(filename))
+                print("{}.png is not RGB 3 channel image".format(filename[-1]))
                 break
-            #elif height*width > 750*750:
-            #    print("{}.png' size is large. Recommend a size smaller than 750x750.".format(filename))
             else:
-                VDSR_upscale = VDSR_sr(sess, VDSR, label.copy(), scale=scale)
-                bicubic_upscale = bicubic_sr(label.copy(), scale=scale)
+                # Bicubic
+                bicubic_upscale = bicubic_sr(label.copy(), scale_x, scale_y)
+                cv2.imwrite('{}/{}.png'.format(result_save_path, '{}_bicubic_{}x{}'.format(filename[-1], out_x, out_y)), bicubic_upscale)
+
+                # VDSR
+                iimg_batch.append(VDSR_preproc(label.copy(), scale_x, scale_y))
+                if (total_img % args.batch == 0) or ( total_img == len(images_list)) :
+                  iimg_batch = np.stack(iimg_batch, axis=0)
+                  VDSR_upscale = VDSR_sr(sess, VDSR, iimg_batch.copy())
+
+                  for i in range(VDSR_upscale.shape[0]):
+                    cv2.imwrite('{}/{}.png'.format(result_save_path, '{}_VDSR_{}x{}'.format(filename[i], out_x, out_y)), VDSR_upscale[i])
 
-                cv2.imwrite('{}/{}.png'.format(result_save_path, '{}_bicubic_{}x'.format(filename, scale)), bicubic_upscale)
-                cv2.imwrite('{}/{}.png'.format(result_save_path, '{}_VDSR_{}x'.format(filename, scale)), VDSR_upscale)
\ No newline at end of file
+                  iimg_batch = list()
+                  filename = list()
diff --git a/VDSR/run b/VDSR/run
new file mode 100755
index 0000000..d8b329e
--- /dev/null
+++ b/VDSR/run
@@ -0,0 +1,4 @@
+#! /bin/bash
+
+python3 ./demo.py --image_in "$@"
+
