diff --git a/darknet.py b/darknet.py
index f77d3c1..f5ad2c1 100644
--- a/darknet.py
+++ b/darknet.py
@@ -211,7 +211,7 @@ class Darknet19(nn.Module):
         iou_pred = F.sigmoid(global_average_pool_reshaped[:, :, :, 4:5])
 
         score_pred = global_average_pool_reshaped[:, :, :, 5:].contiguous()
-        prob_pred = F.softmax(score_pred.view(-1, score_pred.size()[-1])).view_as(score_pred)  # noqa
+        prob_pred = F.softmax(score_pred.view(-1, score_pred.size()[-1])).view(score_pred.size())  # noqa
 
         # for training
         if self.training:
diff --git a/demo.py b/demo.py
index abaf620..140d928 100644
--- a/demo.py
+++ b/demo.py
@@ -1,4 +1,5 @@
 import os
+import sys
 import cv2
 import numpy as np
 from torch.multiprocessing import Pool
@@ -8,6 +9,9 @@ import utils.yolo as yolo_utils
 import utils.network as net_utils
 from utils.timer import Timer
 import cfgs.config as cfg
+import mipso_custom
+if (os.getenv('ZEBRA_INSTALL_DIR')):
+    from zebraRunner import zebra
 
 # This prevents deadlocks in the data loader, caused by
 # some incompatibility between pytorch and cv2 multiprocessing.
@@ -15,13 +19,6 @@ import cfgs.config as cfg
 cv2.setNumThreads(0)
 
 
-def preprocess(fname):
-    # return fname
-    image = cv2.imread(fname)
-    im_data = np.expand_dims(
-        yolo_utils.preprocess_test((image, None, cfg.multi_scale_inp_size), 0)[0], 0)
-    return image, im_data
-
 
 # hyper-parameters
 # npz_fname = 'models/yolo-voc.weights.npz'
@@ -37,57 +34,123 @@ net = Darknet19()
 net_utils.load_net(trained_model, net)
 # net.load_from_npz(npz_fname)
 # net_utils.save_net(h5_fname, net)
-net.cuda()
+#net.cuda()
 net.eval()
 print('load model succ...')
 
 t_det = Timer()
 t_total = Timer()
-im_fnames = sorted((fname
-                    for fname in os.listdir(im_path)
-                    if os.path.splitext(fname)[-1] == '.jpg'))
-im_fnames = (os.path.join(im_path, fname) for fname in im_fnames)
-pool = Pool(processes=1)
-
-for i, (image, im_data) in enumerate(pool.imap(
-        preprocess, im_fnames, chunksize=1)):
+
+if len(sys.argv) > 1:
+    in_file = sys.argv[1]
+else:
+    in_file = im_path + "/2007_000039.jpg"
+
+if len(sys.argv) > 2:
+    batch = int(sys.argv[2])
+else:
+    batch = 1
+
+if len(sys.argv) > 3:
+    loop = sys.argv[3] == '1'
+else:
+    loop = False
+
+if len(sys.argv) > 4:
+    out_path = sys.argv[4]
+else:
+    out_path = None
+
+capture = mipso_custom.mipso_opencv_capture(in_file)
+pauseMode = None
+image_data_batch = []
+capture_image = []
+first_capture = 1
+firstShow = True
+
+while len(capture) > 0:
+    for cap in capture:
+        res, img = cap.read()
+        if loop and img is None:
+            cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
+            _, img = cap.read()
+        if first_capture and out_path is not None:
+            assert (len(capture) == 1), 'saving video works only with single input'
+            out_image = []
+            height, width, _ = img.shape
+            fourcc = cv2.VideoWriter_fourcc(*'XVID')
+            fps = max(1, round(capture[0].get(cv2.CAP_PROP_FPS)))
+            videoWriter = cv2.VideoWriter(out_path, fourcc, fps, (width, height))
+            first_capture = 0
+        if img is None:
+            capture = []
+            if len(image_data_batch) > 0:
+                batch = 1
+        else:
+            capture_image.append(img)
+            image_data_batch.append(
+              yolo_utils.preprocess_test((img, None, cfg.multi_scale_inp_size), 0)[0])
+
+    if len(image_data_batch) < batch:
+        continue
+
     t_total.tic()
     im_data = net_utils.np_to_variable(
-        im_data, is_cuda=True, volatile=True).permute(0, 3, 1, 2)
+        np.asarray(image_data_batch) , is_cuda=False, volatile=True).permute(0, 3, 1, 2)
     t_det.tic()
-    bbox_pred, iou_pred, prob_pred = net(im_data)
+    if (os.getenv('ZEBRA_INSTALL_DIR')):
+        bbox_pred, iou_pred, prob_pred = zebra.run(net, im_data)
+    else:
+        bbox_pred, iou_pred, prob_pred = net(im_data)
     det_time = t_det.toc()
     # to numpy
     bbox_pred = bbox_pred.data.cpu().numpy()
     iou_pred = iou_pred.data.cpu().numpy()
     prob_pred = prob_pred.data.cpu().numpy()
 
-    # print bbox_pred.shape, iou_pred.shape, prob_pred.shape
+    for idx, (img, _bbox_pred, _iou_pred, _prob_pred) in enumerate(zip(capture_image, bbox_pred, iou_pred, prob_pred)):
+        # print bbox_pred.shape, iou_pred.shape, prob_pred.shape
 
-    bboxes, scores, cls_inds = yolo_utils.postprocess(
-        bbox_pred, iou_pred, prob_pred, image.shape, cfg, thresh)
+        bboxes, scores, cls_inds = yolo_utils.postprocess(
+            np.expand_dims(_bbox_pred, axis=0), np.expand_dims(_iou_pred, axis=0), np.expand_dims(_prob_pred, axis=0), img.shape, cfg, thresh)
 
-    im2show = yolo_utils.draw_detection(image, bboxes, scores, cls_inds, cfg)
+        draw_img = yolo_utils.draw_detection(img, bboxes, scores, cls_inds, cfg)
 
-    if im2show.shape[0] > 1100:
-        im2show = cv2.resize(im2show,
-                             (int(1000. *
-                                  float(im2show.shape[1]) / im2show.shape[0]),
-                              1000))
-    cv2.imshow('test', im2show)
+        total_time = t_total.toc()
+        # wait_time = max(int(60 - total_time * 1000), 1)
 
-    total_time = t_total.toc()
-    # wait_time = max(int(60 - total_time * 1000), 1)
-    cv2.waitKey(0)
-
-    if i % 1 == 0:
         format_str = 'frame: %d, ' \
                      '(detection: %.1f Hz, %.1f ms) ' \
                      '(total: %.1f Hz, %.1f ms)'
         print((format_str % (
-            i,
+            idx,
             1. / det_time, det_time * 1000,
             1. / total_time, total_time * 1000)))
 
         t_total.clear()
         t_det.clear()
+
+        mipso_custom.mipso_window_info(draw_img, idx, "PYT YOLOV2", det_time)
+        if out_path is None:
+            if firstShow:
+                height, width, _ = draw_img.shape
+                mipso_custom.mipso_window_init(idx, width, height)
+            cv2.imshow(str(idx), draw_img)
+        else:
+            out_image.append(draw_img)
+    firstShow = False
+    image_data_batch = []
+    capture_image = []
+    if out_path is None:
+        choice = cv2.waitKey(1)
+    else:
+        choice = 0
+    choice = mipso_custom.mipso_process_key(choice)
+    if choice == 27: break
+
+if out_path is not None:
+    print("No more input, encoding capture...")
+    for v in out_image:
+        videoWriter.write(v)
+    videoWriter.release()
+
diff --git a/layers/reorg/reorg_layer.py b/layers/reorg/reorg_layer.py
index 42faf30..b536c88 100644
--- a/layers/reorg/reorg_layer.py
+++ b/layers/reorg/reorg_layer.py
@@ -1,6 +1,6 @@
 import torch
 from torch.autograd import Function
-from ._ext import reorg_layer
+#from ._ext import reorg_layer
 
 
 class ReorgFunction(Function):
@@ -50,5 +50,19 @@ class ReorgLayer(torch.nn.Module):
         self.stride = stride
 
     def forward(self, x):
-        x = ReorgFunction(self.stride)(x)
+        #x = ReorgFunction(self.stride)(x)
+        stride = self.stride
+        assert(x.data.dim() == 4)
+        B = x.data.size(0)
+        C = x.data.size(1)
+        H = x.data.size(2)
+        W = x.data.size(3)
+        assert(H % stride == 0)
+        assert(W % stride == 0)
+        ws = stride
+        hs = stride
+        x = x.view(B, C, H//hs, hs, W//ws, ws).transpose(3,4).contiguous()
+        x = x.view(B, C, H//hs*W//ws, hs*ws).transpose(2,3).contiguous()
+        x = x.view(B, C, hs*ws, H//hs, W//ws).transpose(1,2).contiguous()
+        x = x.view(B, hs*ws*C, H//hs, W//ws)
         return x
diff --git a/make.sh b/make.sh
index c73fb56..ba8db26 100755
--- a/make.sh
+++ b/make.sh
@@ -1,21 +1,21 @@
 #!/usr/bin/env bash
 
-CUDA_PATH=/usr/local/cuda/
+#CUDA_PATH=/usr/local/cuda/
 
 cd utils
-python build.py build_ext --inplace
+python3 build.py build_ext --inplace
 cd ../
 
-cd layers/reorg/src
-echo "Compiling reorg layer kernels by nvcc..."
-nvcc -c -o reorg_cuda_kernel.cu.o reorg_cuda_kernel.cu -x cu -Xcompiler -fPIC -arch=sm_52
-cd ../
-python build.py
-cd ../
+#cd layers/reorg/src
+#echo "Compiling reorg layer kernels by nvcc..."
+#nvcc -c -o reorg_cuda_kernel.cu.o reorg_cuda_kernel.cu -x cu -Xcompiler -fPIC -arch=sm_52
+#cd ../
+#python build.py
+#cd ../
 
-cd roi_pooling/src/cuda
-echo "Compiling roi_pooling kernels by nvcc..."
-nvcc -c -o roi_pooling_kernel.cu.o roi_pooling_kernel.cu -x cu -Xcompiler -fPIC -arch=sm_52
-cd ../../
-python build.py
-cd ../
+#cd roi_pooling/src/cuda
+#echo "Compiling roi_pooling kernels by nvcc..."
+#nvcc -c -o roi_pooling_kernel.cu.o roi_pooling_kernel.cu -x cu -Xcompiler -fPIC -arch=sm_52
+#cd ../../
+#python build.py
+#cd ../
diff --git a/mipso_custom.py b/mipso_custom.py
new file mode 100644
index 0000000..69a97ef
--- /dev/null
+++ b/mipso_custom.py
@@ -0,0 +1,232 @@
+
+import cv2
+import os
+
+############################################################
+############################################################
+
+# the application will open several window and place them on the desktop at
+# specific location. The below variables allow to configure the location
+
+# this is the X/Y offset for window position
+WINDOW_X_OFFSET         = int(os.environ.get("WINDOW_X_OFFSET")         or 0)
+WINDOW_Y_OFFSET         = int(os.environ.get("WINDOW_Y_OFFSET")         or 0)
+
+# this is the number of window per row
+WINDOW_PER_ROW          = int(os.environ.get("WINDOW_PER_ROW")          or 3)
+
+# this is a scaling factor to reduce the window dimension (2: window will be 2x smaller)
+WINDOW_RATIO            = float(os.environ.get("WINDOW_RATIO")          or 1)
+
+# this force the width and height of the video
+WINDOW_WIDTH            = int(os.environ.get("WINDOW_WIDTH")            or 0)
+WINDOW_HEIGHT           = int(os.environ.get("WINDOW_HEIGHT")           or 0)
+
+# this is the index position to place a window so a slide can be displayed. For instance, in a 3x3 configuration use 4 to let the center empty
+WINDOW_SLIDE_IDX        = int(os.environ.get("WINDOW_SLIDE_IDX")        or 4)
+
+# this is the number of batch (usually the number of cores) per system
+BATCH_PER_SYSTEM        = int(os.environ.get("BATCH_PER_SYSTEM")        or 1)
+
+# this is the number of system per board
+SYSTEM_PER_BOARD        = int(os.environ.get("SYSTEM_PER_BOARD")        or 2)
+
+# show info/FPS by default
+SHOW_INFO               = int(os.environ.get("SHOW_INFO")               or 0)
+SHOW_FPS                = int(os.environ.get("SHOW_FPS")                or 0)
+
+
+# enable the MJPG mode
+OPENCV_CAMERA_MJPG      = int(os.environ.get("OPENCV_CAMERA_MJPG")      or 1)
+# force camera width/height
+OPENCV_CAMERA_WIDTH     = int(os.environ.get("OPENCV_CAMERA_WIDTH")     or 0)
+OPENCV_CAMERA_HEIGHT    = int(os.environ.get("OPENCV_CAMERA_HEIGHT")    or 0)
+
+
+############################################################
+############################################################
+
+# only for YoloV2:
+def mipso_get_interpolation():
+    return cv2.INTER_NEAREST
+    return cv2.INTER_LINEAR
+    #return cv2.INTER_LANCZOS4
+
+# only for YoloV2
+def mipso_camera_reduce_delay():
+    return False # normal execution: capture / inference / display from capture
+    return True # reduce delay execution: inference on prev capture / capture / display from capture using previous inference
+
+# only for YoloV2
+def mipso_box_rounding(i):
+    return i
+    round = 20
+    return ((i + round) // (2*round) ) * 2*round
+
+def mipso_camera_init(c):
+    print ("Initial camera resolution {}x{} @ {}".format(
+        c.get(cv2.CAP_PROP_FRAME_WIDTH),
+        c.get(cv2.CAP_PROP_FRAME_HEIGHT),
+        c.get(cv2.CAP_PROP_FPS)))
+    if OPENCV_CAMERA_WIDTH != 0:
+        c.set(cv2.CAP_PROP_FRAME_WIDTH , OPENCV_CAMERA_WIDTH)
+    if OPENCV_CAMERA_HEIGHT != 0:
+        c.set(cv2.CAP_PROP_FRAME_HEIGHT , OPENCV_CAMERA_HEIGHT)
+    if OPENCV_CAMERA_MJPG != 0:
+        c.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter.fourcc('M', 'J', 'P', 'G'))
+    print ("Using camera resolution {}x{} @ {}".format(
+        c.get(cv2.CAP_PROP_FRAME_WIDTH),
+        c.get(cv2.CAP_PROP_FRAME_HEIGHT),
+        c.get(cv2.CAP_PROP_FPS)))
+
+def mipso_window_init(idx, width, height):
+    cv2.namedWindow(str(idx), cv2.WINDOW_GUI_NORMAL | cv2.WINDOW_FREERATIO)
+    #cv2.namedWindow(str(idx), cv2.WINDOW_NORMAL)
+
+    if WINDOW_WIDTH != 0 and WINDOW_HEIGHT != 0:
+        cur_width = WINDOW_WIDTH
+        cur_height = WINDOW_HEIGHT
+    else:
+        cur_width = int(width // WINDOW_RATIO)
+        cur_height = int(height // WINDOW_RATIO)
+
+    cv2.resizeWindow(str(idx), (cur_width, cur_height))
+    board=0
+    system=0
+    core=0
+    if 'ZEBRA_RUNSESSION_ENABLECORES' in os.environ:
+        c = os.environ['ZEBRA_RUNSESSION_ENABLECORES'].split(':')[0].split('_')
+        if len(c[0]) > 0:
+            board = int(c[0][1:])
+        if len(c) > 1:
+            system = int(c[1][1:])
+        if len(c) > 2:
+            core = int(c[2][1:])
+
+    cur_idx = idx + core + BATCH_PER_SYSTEM * ( system + SYSTEM_PER_BOARD * board)
+    # in case we want to put slide somewhere
+    if cur_idx >= WINDOW_SLIDE_IDX:
+        cur_idx = cur_idx + 1
+    pos_x = WINDOW_X_OFFSET + int( (cur_idx % WINDOW_PER_ROW)*cur_width)
+    pos_y = WINDOW_Y_OFFSET + int( 0 + (cur_idx // WINDOW_PER_ROW)*cur_height)
+
+    print("Move window {} {}x{} for system {} @ ({} , {})".format(idx, cur_width, cur_height, system, pos_x, pos_y))
+    cv2.moveWindow(str(idx), pos_x, pos_y)
+
+def mipso_parse_input(file):
+    mode='file'
+    for part in file.split(':'):
+        if 'camera' == part:
+            mode='camera'
+            continue
+        if part.isdigit():
+            yield mode, int(part)
+        else:
+            mode='file'
+            yield mode, part
+
+
+
+def mipso_opencv_capture(file):
+    """
+    return a list of opencv capture device
+    """
+    camera = []
+    # TODO: use a better handling of the different mode (class)
+    if 'camera' == file:
+        # open all camera
+        camera_idx=0
+        while True:
+            c = cv2.VideoCapture(camera_idx)
+            if c.isOpened() == False:
+                break
+            camera.append(c)
+            mipso_camera_init(c)
+            camera_idx = camera_idx + 1
+    else:
+        for mode, url in mipso_parse_input(file):
+            c = cv2.VideoCapture(url)
+            if c.isOpened() == False:
+                print("Error opening source {} {}".format(mode, url))
+                break
+            if mode == 'camera':
+                mipso_camera_init(c)
+            camera.append(c)
+
+    assert len(camera) > 0, 'Cannot capture source'
+    return camera
+
+# TODO: create a Mipso class
+showHelp = False
+pauseMode = False
+showWindowInfo = SHOW_INFO != 0
+showFps = SHOW_FPS != 0
+
+def mipso_process_key(key):
+    global showHelp
+    global pauseMode
+    global showWindowInfo
+    global showFps
+
+    if pauseMode:
+        print ("pause mode, press 'p' to play or any other key to move to the next frame")
+    while True:
+        if key == 27:
+            return key
+        if key > 0 and chr(key) in 'h':
+            showHelp = not showHelp
+        if key > 0 and chr(key) in 'p':
+            pauseMode = not pauseMode
+        if key > 0 and chr(key) in 'i':
+            showWindowInfo = not showWindowInfo
+        if key > 0 and chr(key) in 'f':
+            showFps = not showFps
+        if not pauseMode or key != -1:
+            break
+        key = cv2.waitKey(1)
+    return key
+
+def print_help(frame):
+
+    HELP="\
+Key usage:\n\
+    ESC : exit the demo\n\
+    h   : toggle displaying this help\n\
+    p   : pause the video (any other key will do frame by frame)\n\
+    i   : toggle showing network information\n\
+    f   : toggle showing FPS\n\
+"
+    scale = 1
+    if frame.shape[1] < 1240:
+        scale = scale * frame.shape[1] / 1240
+    for y, line in enumerate(HELP.split('\n')):
+        cv2.putText(frame, line, (20, int(scale*(200 + y * 40))), cv2.FONT_HERSHEY_SIMPLEX,
+                    scale, (255,255,0), 1)
+
+
+def print_text(frame, x, y, text, scale=1.2):
+    font                   = cv2.FONT_HERSHEY_SIMPLEX
+    bottomLeftCornerOfText = (10,500)
+    fontScale              = scale
+    fontColor              = (0,0,255)
+    lineType               = 2 if scale >= 1 else 1
+
+    cv2.putText(frame, text, (x, y),
+        font,
+        fontScale,
+        fontColor,
+        lineType)
+
+def mipso_window_info(f, idx, name, latency):
+    if showHelp:
+        print_help(f)
+    if showWindowInfo:
+        scale = 1
+        if f.shape[1] < 500:
+            scale = scale * f.shape[1] / 500
+        if showFps:
+            print_text( f, 10, int(scale*30), "Zebra: {} FPS={}".format(name, str(int(1/latency))), scale )
+        else:
+            print_text( f, 10, int(scale*30), "Zebra: {}".format(name), scale)
+        #print_text(f, 10, 50, "Latency is: " + str(int(1000*latency)) + " ms. FPS is: " + str(int(1/latency)) + " img/s")
+
diff --git a/run b/run
new file mode 100755
index 0000000..0bd7bef
--- /dev/null
+++ b/run
@@ -0,0 +1,19 @@
+#! /bin/bash
+
+batch=1
+loop=0
+out_file=
+
+in="$1"
+shift
+
+while [ $# -gt 0 ]
+do
+  [ "$1" = "--batch" ] && batch=$2 && shift 2 && continue
+  [ "$1" = "--loop" ] && loop=1 && shift && continue
+  [ "$1" = "--out_file" ] && out_file=$2 && shift 2 && continue
+  shift
+done
+
+python3 demo.py "$in" $batch $loop $out_file
+
diff --git a/utils/build.py b/utils/build.py
index 91fce6f..46fba1b 100644
--- a/utils/build.py
+++ b/utils/build.py
@@ -63,7 +63,7 @@ def locate_cuda():
     return cudaconfig
 
 
-CUDA = locate_cuda()
+#CUDA = locate_cuda()
 
 # Obtain the numpy include directory.  This logic works across numpy versions.
 try:
@@ -137,25 +137,25 @@ ext_modules = [
         extra_compile_args={'gcc': ["-Wno-cpp", "-Wno-unused-function"]},
         include_dirs=[numpy_include]
     ),
-    Extension('nms.gpu_nms',
-              ['nms/nms_kernel.cu', 'nms/gpu_nms.pyx'],
-              library_dirs=[CUDA['lib64']],
-              libraries=['cudart'],
-              language='c++',
-              runtime_library_dirs=[CUDA['lib64']],
+#    Extension('nms.gpu_nms',
+#              ['nms/nms_kernel.cu', 'nms/gpu_nms.pyx'],
+#              library_dirs=[CUDA['lib64']],
+#              libraries=['cudart'],
+#              language='c++',
+#              runtime_library_dirs=[CUDA['lib64']],
               # this syntax is specific to this build system
               # we're only going to use certain compiler args with
               # nvcc and not with gcc
               # the implementation of this trick is in
               # customize_compiler() below
-              extra_compile_args={'gcc': ["-Wno-unused-function"],
-                                  'nvcc': ['-arch=sm_35',
-                                           '--ptxas-options=-v',
-                                           '-c',
-                                           '--compiler-options',
-                                           "'-fPIC'"]},
-              include_dirs=[numpy_include, CUDA['include']]
-              ),
+#              extra_compile_args={'gcc': ["-Wno-unused-function"],
+#                                  'nvcc': ['-arch=sm_35',
+#                                           '--ptxas-options=-v',
+#                                           '-c',
+#                                           '--compiler-options',
+#                                           "'-fPIC'"]},
+#              include_dirs=[numpy_include, CUDA['include']]
+#              ),
     Extension(
         'pycocotools._mask',
         sources=['pycocotools/maskApi.c', 'pycocotools/_mask.pyx'],
diff --git a/utils/network.py b/utils/network.py
index 600d1c6..0d2d5ef 100644
--- a/utils/network.py
+++ b/utils/network.py
@@ -63,8 +63,9 @@ def load_net(fname, net):
     import h5py
     h5f = h5py.File(fname, mode='r')
     for k, v in list(net.state_dict().items()):
-        param = torch.from_numpy(np.asarray(h5f[k]))
-        v.copy_(param)
+        if k in h5f:
+            param = torch.from_numpy(np.asarray(h5f[k]))
+            v.copy_(param)
 
 
 def load_pretrained_npy(faster_rcnn_model, fname):
diff --git a/utils/nms_wrapper.py b/utils/nms_wrapper.py
index 1c50e4c..3a82cdc 100644
--- a/utils/nms_wrapper.py
+++ b/utils/nms_wrapper.py
@@ -6,7 +6,7 @@
 # --------------------------------------------------------
 
 from .nms.cpu_nms import cpu_nms
-from .nms.gpu_nms import gpu_nms
+#from .nms.gpu_nms import gpu_nms
 
 
 # def nms(dets, thresh, force_cpu=False):
@@ -20,7 +20,7 @@ from .nms.gpu_nms import gpu_nms
 #         return cpu_nms(dets, thresh)
 
 
-def nms(dets, thresh, force_cpu=False):
+def nms(dets, thresh, force_cpu=True):
     """Dispatch to either CPU or GPU NMS implementations."""
 
     if dets.shape[0] == 0:
